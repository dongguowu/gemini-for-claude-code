# Required: Your Google AI Studio API key (only if not using a custom proxy)
GEMINI_API_KEY="your-google-ai-studio-key"

# Optional: Custom Proxy Settings (if you want to route requests through a different service)
# If CUSTOM_PROXY_URL is set, GEMINI_API_KEY is not required.
CUSTOM_PROXY_URL="" # Example: "https://my-openai-compatible-proxy.com/v1"
CUSTOM_PROXY_API_KEY="" # The API key for your custom proxy service

# Optional: Model mappings for Claude Code aliases
BIG_MODEL="gemini-1.5-pro-latest"    # For 'sonnet' or 'opus' requests
SMALL_MODEL="gemini-1.5-flash-latest" # For 'haiku' requests

# Optional: Server settings
HOST="0.0.0.0"
PORT="8082"
LOG_LEVEL="WARNING"  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# Optional: Performance and reliability settings
MAX_TOKENS_LIMIT="8192"           # Max tokens for Gemini responses
REQUEST_TIMEOUT="90"              # Request timeout in seconds
MAX_RETRIES="2"                   # LiteLLM retries to Gemini
MAX_STREAMING_RETRIES="12"         # Streaming-specific retry attempts

# Optional: Streaming control (use if experiencing issues)
FORCE_DISABLE_STREAMING="false"     # Disable streaming globally
EMERGENCY_DISABLE_STREAMING="false" # Emergency streaming disable
